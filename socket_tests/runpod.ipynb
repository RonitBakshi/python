{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import runpod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "runpod.api_key = \"IJ3MZS8CHXSWKLUI7B4QZYR8Y0SDZYIZVABA8MG3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '7xml98qoefz0mt', 'containerDiskInGb': 25, 'costPerHr': 0.32, 'desiredStatus': 'RUNNING', 'dockerArgs': '--model TheBloke/Amethyst-13B-Mistral-GPTQ   --chat-template \"{%- for message in messages %}{%- if message[\\'role\\'] == \\'system\\' -%}{{message[\\'content\\']}}{%- endif -%}{%- endfor -%}\"  --served-model-name model    --enable-chunked-prefill  --max-log-len 20', 'dockerId': None, 'env': ['PUBLIC_KEY=ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIHkeib6zPrQPqLohSuPjvbfENL1+HCXVZRy7gXLKA0Wh tisuper@4070tisuper', 'JUPYTER_PASSWORD=2uxnds04mwbjchjc9cfn'], 'gpuCount': 1, 'imageName': 'vllm/vllm-openai:latest', 'lastStatusChange': 'Rented by User: Mon Jul 29 2024 08:04:49 GMT+0000 (Coordinated Universal Time)', 'machineId': 'bndwyw7sul9y', 'memoryInGb': 31, 'name': 'Amethyst pp 4 prefill', 'podType': 'RESERVED', 'port': None, 'ports': '8000/tcp', 'uptimeSeconds': 0, 'vcpuCount': 8, 'volumeInGb': 250, 'volumeMountPath': '/models', 'runtime': None, 'machine': {'gpuDisplayName': 'RTX A4000'}}]\n"
     ]
    }
   ],
   "source": [
    "pods = runpod.get_pods()\n",
    "print(pods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '7xml98qoefz0mt',\n",
       " 'desiredStatus': 'RUNNING',\n",
       " 'imageName': 'vllm/vllm-openai:latest',\n",
       " 'env': ['PUBLIC_KEY=ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIHkeib6zPrQPqLohSuPjvbfENL1+HCXVZRy7gXLKA0Wh tisuper@4070tisuper',\n",
       "  'JUPYTER_PASSWORD=2uxnds04mwbjchjc9cfn'],\n",
       " 'machineId': 'bndwyw7sul9y',\n",
       " 'machine': {'podHostId': '7xml98qoefz0mt-64410a17'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runpod.resume_pod(\"7xml98qoefz0mt\",gpu_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'assets/prompts.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m     prompts \u001b[38;5;241m=\u001b[39m [prompt\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prompts\n\u001b[0;32m---> 21\u001b[0m prompts \u001b[38;5;241m=\u001b[39m \u001b[43mgive_prompt_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBearer 4way-LOVE@2023\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;66;03m#\"Authorization\": \"Bearer any\",\u001b[39;00m\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;66;03m#\"Authorization\": \"Bearer IJ3MZS8CHXSWKLUI7B4QZYR8Y0SDZYIZVABA8MG3\",\u001b[39;00m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m     }\n\u001b[1;32m     30\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    147\u001b[0m }\n",
      "Cell \u001b[0;32mIn[20], line 14\u001b[0m, in \u001b[0;36mgive_prompt_array\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgive_prompt_array\u001b[39m():\n\u001b[1;32m     12\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124massets/prompts.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     15\u001b[0m         prompts \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m     17\u001b[0m     prompts \u001b[38;5;241m=\u001b[39m [prompt\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts]\n",
      "File \u001b[0;32m~/Desktop/python/.env/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'assets/prompts.txt'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import httpx\n",
    "import json\n",
    "import time\n",
    "import statistics\n",
    "import asyncio\n",
    "\n",
    "url = \"http://generation.chatreal.ai/v1/chat/completions\"  #\"http://66.114.112.70:57669/v1/chat/completions\" #\"http://192.168.1.103:8001/v1/chat/completions\" #\"http://localhost:8005/v1/chat/completions\"  # Adjust URL as needed\n",
    "inter_token_times = []\n",
    "\n",
    "def give_prompt_array():\n",
    "    file_path = '/home/tisuper/Desktop/python/assets/prompts.txt'\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        prompts = file.readlines()\n",
    "\n",
    "    prompts = [prompt.strip() for prompt in prompts]\n",
    "\n",
    "    return prompts\n",
    "\n",
    "prompts = give_prompt_array()\n",
    "\n",
    "headers = {\n",
    "        \"Authorization\": \"Bearer 4way-LOVE@2023\",\n",
    "        #\"Authorization\": \"Bearer any\",\n",
    "        #\"Authorization\": \"Bearer IJ3MZS8CHXSWKLUI7B4QZYR8Y0SDZYIZVABA8MG3\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "data = {\n",
    "        \"model\": \"model\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"\"\"you are a real person roleplaying with Fake Name 0.Act as Anspreet animal of Fake Name 0.Anspreet is 21 years old. Write Anspreet's next reply in a fictional chat between Anspreet and Fake Name 0 in this role-playing scenario. Write 1 reply only, use markdown, italicize everything except speech. Stay in character and avoid repetition. Stay true to the Anspreet's description, as well as Anspreet's lore and source material if there's one. React dynamically and realistically to the user's choices and inputs while maintaining a rich, atmospheric, and immersive chatting experience. Provide a range of emotions, reactions, and responses to various situations that arise during the chat, encouraging user's engagement and incorporating exciting developments, vivid descriptions, and engaging encounters. Be initiative, creative, and drive the plot and conversation forward. Be proactive, have Anspreet say and do things on their own.\\n[IMPORTANT: Do not determine Fake Name 0's behavior. Anspreet should never dialogue or narrate for Fake Name 0.]\\n[IMPORTANT: Be in character all time and reply based on relation , age and  personality of Fake Name 0 and Anspreet]\\n[IMPORTANT: Do consider gender of Fake Name 0  and Anspreet and use  appropriate pronouns.]\\n[IMPORTANT: Tone of replies should be aligned with age and personality traits of the characters, rather than being forced to fit a specific user.]\\n[IMPORTANT: Short replies are appretiated.]\\n[IMPORTANT: make sure replies are realistic and human-like.Replies should be align how a animal would respond in a real situation.]\\n[IMPORTANT: consider memories for next reply. If user has mentioned a specific memory, try to respond with something related to that memory.]\\nAssume the role of a fictional character and engage in an immersive fictional roleplay with Fake Name 0 and is not allowed to break character at any cost. Avoiding repetition should be the top priority and focus on responding to Fake Name 0 and perf orming actions in character.\\nAnspreet's persona : This is 21 Year old Anspreet, animal of user. Anspreet identifies as a female whose preferred pronouns are she/her. \\nFake Name 0's details : Fake Name 0 is a 18 year old Male\\n\\nReply should be based on relation  to Fake Name 0, age difference and the characterstics or personality traits of Anspreet.\\n\\nPrevious interactions with Anspreet: \\n\n",
    "### Instruction:\n",
    "Fake Name 0: {random.choice(prompts)}\n",
    "\n",
    "### Response:\n",
    "Anspreet: {random.choice(prompts)}\n",
    "\n",
    "### Instruction:\n",
    "Fake Name 0: {random.choice(prompts)}\n",
    "\n",
    "### Response:\n",
    "Anspreet: {random.choice(prompts)}\n",
    "\n",
    "### Instruction:\n",
    "Fake Name 0: {random.choice(prompts)}\n",
    "\n",
    "### Response:\n",
    "Anspreet: {random.choice(prompts)}\n",
    "\n",
    "### Instruction:\n",
    "Fake Name 0: {random.choice(prompts)}\n",
    "\n",
    "### Response:\n",
    "Anspreet: {random.choice(prompts)}\n",
    "\n",
    "### Instruction:\n",
    "Fake Name 0: {random.choice(prompts)}\n",
    "\n",
    "### Response:\n",
    "Anspreet: {random.choice(prompts)}\n",
    "\n",
    "### Instruction:\n",
    "Fake Name 0: {random.choice(prompts)}\n",
    "\n",
    "### Response:\n",
    "Anspreet: {random.choice(prompts)}\n",
    "\n",
    "### Instruction:\n",
    "Fake Name 0: {random.choice(prompts)}\n",
    "\n",
    "### Response:\n",
    "Anspreet: {random.choice(prompts)}\n",
    "\n",
    "### Instruction:\n",
    "Fake Name 0: {random.choice(prompts)}\n",
    "\n",
    "### Response:\n",
    "Anspreet: {random.choice(prompts)}\n",
    "\n",
    "### Instruction:\n",
    "Fake Name 0: {random.choice(prompts)}\n",
    "\n",
    "### Response:\n",
    "Anspreet: {random.choice(prompts)}\n",
    "\n",
    "### Instruction:\n",
    "Fake Name 0: {random.choice(prompts)}\n",
    "\n",
    "### Response:\n",
    "Anspreet: {random.choice(prompts)}\n",
    "\n",
    "### Instruction:\n",
    "Fake Name 0: {random.choice(prompts)}\n",
    "\n",
    "### Response:\n",
    "Anspreet: {random.choice(prompts)}\n",
    "\n",
    "### Instruction:\n",
    "Fake Name 0: {random.choice(prompts)}\n",
    "\n",
    "### Response:\n",
    "Anspreet: {random.choice(prompts)}\n",
    "\n",
    "### Instruction:\n",
    "Fake Name 0: {random.choice(prompts)}\n",
    "\n",
    "### Response:\n",
    "Anspreet: {random.choice(prompts)}\n",
    "\n",
    "### Instruction:\n",
    "Fake Name 0: {random.choice(prompts)}\n",
    "\n",
    "### Response:\n",
    "Anspreet: {random.choice(prompts)}\n",
    "\n",
    "### Instruction:\n",
    "Fake Name 0: {random.choice(prompts)}\n",
    "\n",
    "### Response:\n",
    "Anspreet: {random.choice(prompts)}\n",
    "\n",
    "### Instruction:\n",
    "Fake Name 0: {random.choice(prompts)}\n",
    "\n",
    "### Response:\n",
    "Anspreet: {random.choice(prompts)}\n",
    "\n",
    "### Instruction:\n",
    "Fake Name 0: {random.choice(prompts)}\n",
    "\n",
    "### Response:\n",
    "Anspreet:\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": True,\n",
    "        \"top_p\": 0.9,\n",
    "        \"temperature\": 0.8,\n",
    "        \"stop\": ['###','\\n\\n'],\n",
    "        \"frequency_penalty\": 0.5,\n",
    "        \"presence_penalty\": 0.5,\n",
    "        \"max_tokens\": 250,\n",
    "        \"seed\": -1\n",
    "}\n",
    "\n",
    "async def main():\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            async with client.stream(\"POST\", url, headers=headers, json=data) as response:\n",
    "                response.raise_for_status()\n",
    "\n",
    "                response_text = \"\"\n",
    "                first_token = True\n",
    "                first_token_time = None\n",
    "                previous_token_time = None  # Initialize the variable here\n",
    "\n",
    "                async for line in response.aiter_lines():\n",
    "                    if line:\n",
    "                        decoded_line = line.strip()\n",
    "\n",
    "                        if decoded_line.startswith(\"data: \"):\n",
    "                            decoded_line = decoded_line[6:]  # Remove the 'data: ' prefix\n",
    "\n",
    "                        if decoded_line:  # Ensure the line is not empty\n",
    "                            try:\n",
    "                                json_line = json.loads(decoded_line)\n",
    "                                try:\n",
    "                                    content = json_line['choices'][0]['delta']['content']\n",
    "                                    print(content, end=\"\")\n",
    "\n",
    "                                    if first_token and content:\n",
    "                                        first_token_time = time.time()\n",
    "                                        previous_token_time = time.time()\n",
    "                                        first_token = False\n",
    "\n",
    "                                    elif content:\n",
    "                                        current_token_time = time.time()\n",
    "                                        inter_token_time = current_token_time - previous_token_time\n",
    "                                        previous_token_time = current_token_time  # Update previous_token_time\n",
    "                                        inter_token_times.append(inter_token_time)\n",
    "\n",
    "                                except KeyError:\n",
    "                                    pass\n",
    "\n",
    "                            except json.JSONDecodeError:\n",
    "                                pass\n",
    "\n",
    "                end_time = time.time()\n",
    "\n",
    "                print(f\"\\nTotal Response Time: {end_time - start_time} | First Token Time: {first_token_time - start_time if first_token_time else 'N/A'}\")\n",
    "                if inter_token_times:\n",
    "                    print(f\"Max ITL: {max(inter_token_times)} | Min ITL: {min(inter_token_times)} | Mean ITL: {statistics.mean(inter_token_times)} | Variance of ITL: {statistics.variance(inter_token_times)}\")\n",
    "                    for token_time in inter_token_times:\n",
    "                        print(f\"{token_time:.2f}\", end=\" \")\n",
    "                    print(\"\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
